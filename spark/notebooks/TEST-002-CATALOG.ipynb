{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "877b5fb4-5a05-43ef-a2d1-127989e51b8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import StructType, StructField\n",
    "from pyspark.sql.types import DoubleType, IntegerType,StringType, FloatType\n",
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a94de10e-8fd6-4175-a99c-78990d8680ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "accessKeyId = \"admin\"\n",
    "secretAccessKey = \"password\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e6a38bed-0ebd-431d-b05a-ca7473631e81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# spark = (\n",
    "#     SparkSession.builder\n",
    "#     .master('spark://spark-iceberg:7077')\n",
    "#     .appName(\"Spark Nessie Iceberg Demo\")\n",
    "#     .config(\"spark.driver.memory\", \"16g\")\n",
    "#     .config(\"spark.hadoop.fs.s3a.aws.credentials.provider\",\n",
    "#                  \"org.apache.hadoop.fs.s3a.SimpleAWSCredentialsProvider\")\\\n",
    "#     .config('spark.jars.packages','org.apache.iceberg:iceberg-spark-runtime-3.3_2.12:1.5.2,org.projectnessie.nessie-integrations:nessie-spark-extensions-3.3_2.12:0.96.1')\n",
    "#     .config(\"spark.hadoop.fs.s3a.access.key\", accessKeyId)\n",
    "#     .config(\"spark.hadoop.fs.s3a.secret.key\", secretAccessKey)\n",
    "#     .config(\"spark.hadoop.fs.s3a.path.style.access\", True)\n",
    "#     .config(\"spark.hadoop.fs.s3a.impl\", \"org.apache.hadoop.fs.s3a.S3AFileSystem\")\n",
    "#     .config(\"spark.hadoop.fs.s3a.endpoint\", \"http://minio:9000\")\n",
    "#     .config(\"spark.sql.catalog.nessie.uri\", \"http://nessie:19120/api/v1\")\n",
    "#     .config(\"spark.sql.catalog.nessie.ref\", \"main\")\n",
    "#     .config(\"spark.sql.catalog.nessie.authentication.type\", \"NONE\")\n",
    "#     .config(\"spark.sql.catalog.nessie\", \"org.apache.iceberg.spark.SparkCatalog\")\n",
    "#     .config(\"spark.sql.catalog.nessie.catalog-impl\", \"org.apache.iceberg.nessie.NessieCatalog\")\n",
    "#     .config(\"spark.sql.catalog.nessie.warehouse\", \"s3://warehouse/\")\n",
    "#     .config(\"fs.s3a.connection.ssl.enabled\", \"false\")\n",
    "#     .getOrCreate()\n",
    "# )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8eb7587a-1c8d-41e8-9834-e64ba438a9f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/10/15 15:53:52 WARN SparkSession: Using an existing Spark session; only runtime SQL configurations will take effect.\n"
     ]
    }
   ],
   "source": [
    "spark = (\n",
    "    SparkSession.builder.appName(\"Iceberg-Nessie\")\n",
    "    .config(\"spark.sql.extensions\", \"org.apache.iceberg.spark.extensions.IcebergSparkSessionExtensions\")\n",
    "    .config(\"spark.sql.catalog.lakehouse_prod_catalog\", \"org.apache.iceberg.spark.SparkCatalog\")\n",
    "    .config(\"spark.sql.catalog.lakehouse_prod_catalog.type\", \"nessie\")\n",
    "    .config(\"spark.sql.catalog.lakehouse_prod_catalog.uri\", \"http://nessie:19120/api/v2\")\n",
    "    .config(\"spark.sql.catalog.lakehouse_prod_catalog.ref\", \"main\")\n",
    "    .config(\"spark.sql.catalog.lakehouse_prod_catalog.warehouse\", \"s3a://warehouse/\")\n",
    "    .config(\"spark.sql.catalog.lakehouse_prod_catalog.s3.endpoint\", \"http://minio:9000\")\n",
    "    .config(\"spark.sql.catalog.lakehouse_prod_catalog.s3.path-style-access\", \"true\")\n",
    "    .config(\"spark.sql.catalog.lakehouse_prod_catalog.s3.access-key-id\", \"admin\")\n",
    "    .config(\"spark.sql.catalog.lakehouse_prod_catalog.s3.secret-access-key\", \"password\")\n",
    "    .config(\"spark.hadoop.fs.s3a.connection.ssl.enabled\", \"false\")\n",
    "    .getOrCreate()\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "be3014ed-51f5-4f13-8468-83cf6d9d5f78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+\n",
      "|namespace|\n",
      "+---------+\n",
      "+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SHOW DATABASES\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "8dc070e4-f264-40b5-8cd2-e06ce235d127",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+\n",
      "|      namespace|\n",
      "+---------------+\n",
      "|        test_db|\n",
      "|raw_bronze_zone|\n",
      "+---------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SHOW NAMESPACES\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "59e4ea6e-6dcc-4bf6-8ccb-0fdf0b0e0350",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|             catalog|\n",
      "+--------------------+\n",
      "|lakehouse_prod_ca...|\n",
      "|       spark_catalog|\n",
      "+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SHOW CATALOGS\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b94096d2-0cf3-4a34-ba70-d570f61cd767",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------+-----------+\n",
      "|namespace|tableName|isTemporary|\n",
      "+---------+---------+-----------+\n",
      "+---------+---------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SHOW TABLES IN lakehouse_prod_catalog.raw_bronze_zone\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a599e35d-c810-427e-a893-f35eb24909ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++\n",
      "||\n",
      "++\n",
      "++\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"CREATE NAMESPACE IF NOT EXISTS lakehouse_prod_catalog.raw_bronze_zone;\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9e0cd185-58f4-444f-831d-b4e6a070826b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++\n",
      "||\n",
      "++\n",
      "++\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\n",
    "    \"\"\"\n",
    "        CREATE TABLE IF NOT EXISTS lakehouse_prod_catalog.test_db.sample_table (\n",
    "            id BIGINT,\n",
    "            name STRING\n",
    "        ) USING iceberg;\n",
    "    \"\"\"\n",
    ").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "05096f1b-9c29-407b-8c67-3eee5e308463",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++\n",
      "||\n",
      "++\n",
      "++\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Insert data into the sample_table\n",
    "spark.sql(\n",
    "    \"\"\"\n",
    "        INSERT INTO lakehouse_prod_catalog.test_db.sample_table VALUES\n",
    "        (1, 'Alice'),\n",
    "        (2, 'Bob');\n",
    "    \"\"\"\n",
    ").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "44299bd1-8c74-4abf-be32-daaeb102ef96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+------------+-----------+\n",
      "|namespace|   tableName|isTemporary|\n",
      "+---------+------------+-----------+\n",
      "|  test_db|sample_table|      false|\n",
      "+---------+------------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Insert data into the sample_table\n",
    "spark.sql(\n",
    "    \"\"\"\n",
    "SHOW TABLES;\n",
    "    \"\"\"\n",
    ").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "994c65cd-63e6-447d-ad27-62b41bc445a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: boto3 in /usr/local/lib/python3.12/site-packages (1.40.52)\n",
      "Requirement already satisfied: botocore<1.41.0,>=1.40.52 in /usr/local/lib/python3.12/site-packages (from boto3) (1.40.52)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /usr/local/lib/python3.12/site-packages (from boto3) (1.0.1)\n",
      "Requirement already satisfied: s3transfer<0.15.0,>=0.14.0 in /usr/local/lib/python3.12/site-packages (from boto3) (0.14.0)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.12/site-packages (from botocore<1.41.0,>=1.40.52->boto3) (2.9.0.post0)\n",
      "Requirement already satisfied: urllib3!=2.2.0,<3,>=1.25.4 in /usr/local/lib/python3.12/site-packages (from botocore<1.41.0,>=1.40.52->boto3) (2.5.0)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/site-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.41.0,>=1.40.52->boto3) (1.17.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install boto3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8e69cb30-3f52-4cc2-a108-5196be1357de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>FirstName</th>\n",
       "      <th>LastName</th>\n",
       "      <th>StartDate</th>\n",
       "      <th>ExitDate</th>\n",
       "      <th>Title</th>\n",
       "      <th>Supervisor</th>\n",
       "      <th>ADEmail</th>\n",
       "      <th>BusinessUnit</th>\n",
       "      <th>EmployeeStatus</th>\n",
       "      <th>...</th>\n",
       "      <th>Satisfaction Score</th>\n",
       "      <th>Work-Life Balance Score</th>\n",
       "      <th>Training Date</th>\n",
       "      <th>Training Program Name</th>\n",
       "      <th>Training Type</th>\n",
       "      <th>Training Outcome</th>\n",
       "      <th>Location</th>\n",
       "      <th>Trainer</th>\n",
       "      <th>Training Duration(Days)</th>\n",
       "      <th>Training Cost</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Uriah</td>\n",
       "      <td>Bridges</td>\n",
       "      <td>20-Sep-19</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Production Technician I</td>\n",
       "      <td>Peter Oneill</td>\n",
       "      <td>uriah.bridges@bilearner.com</td>\n",
       "      <td>CCDR</td>\n",
       "      <td>Active</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>15-Jul-23</td>\n",
       "      <td>Leadership Development</td>\n",
       "      <td>Internal</td>\n",
       "      <td>Failed</td>\n",
       "      <td>South Marisa</td>\n",
       "      <td>Taylor Rodriguez</td>\n",
       "      <td>2</td>\n",
       "      <td>606.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Paula</td>\n",
       "      <td>Small</td>\n",
       "      <td>11-Feb-23</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Production Technician I</td>\n",
       "      <td>Renee Mccormick</td>\n",
       "      <td>paula.small@bilearner.com</td>\n",
       "      <td>EW</td>\n",
       "      <td>Active</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>12-Sep-22</td>\n",
       "      <td>Customer Service</td>\n",
       "      <td>External</td>\n",
       "      <td>Incomplete</td>\n",
       "      <td>Tammieville</td>\n",
       "      <td>Kelly Patterson DDS</td>\n",
       "      <td>4</td>\n",
       "      <td>673.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Edward</td>\n",
       "      <td>Buck</td>\n",
       "      <td>10-Dec-18</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Area Sales Manager</td>\n",
       "      <td>Crystal Walker</td>\n",
       "      <td>edward.buck@bilearner.com</td>\n",
       "      <td>PL</td>\n",
       "      <td>Active</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>13-Aug-22</td>\n",
       "      <td>Leadership Development</td>\n",
       "      <td>External</td>\n",
       "      <td>Failed</td>\n",
       "      <td>East Roberthaven</td>\n",
       "      <td>Taylor Thomas</td>\n",
       "      <td>2</td>\n",
       "      <td>413.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Michael</td>\n",
       "      <td>Riordan</td>\n",
       "      <td>21-Jun-21</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Area Sales Manager</td>\n",
       "      <td>Rebekah Wright</td>\n",
       "      <td>michael.riordan@bilearner.com</td>\n",
       "      <td>CCDR</td>\n",
       "      <td>Active</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>15-Dec-22</td>\n",
       "      <td>Project Management</td>\n",
       "      <td>External</td>\n",
       "      <td>Completed</td>\n",
       "      <td>Garzatown</td>\n",
       "      <td>Holly Elliott</td>\n",
       "      <td>3</td>\n",
       "      <td>663.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Jasmine</td>\n",
       "      <td>Onque</td>\n",
       "      <td>29-Jun-19</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Area Sales Manager</td>\n",
       "      <td>Jason Kim</td>\n",
       "      <td>jasmine.onque@bilearner.com</td>\n",
       "      <td>TNS</td>\n",
       "      <td>Active</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>13-Jul-23</td>\n",
       "      <td>Technical Skills</td>\n",
       "      <td>External</td>\n",
       "      <td>Failed</td>\n",
       "      <td>Lake Meganville</td>\n",
       "      <td>Donald Martinez</td>\n",
       "      <td>5</td>\n",
       "      <td>399.03</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 39 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0 FirstName LastName  StartDate ExitDate                    Title  \\\n",
       "0           0     Uriah  Bridges  20-Sep-19      NaN  Production Technician I   \n",
       "1           1     Paula    Small  11-Feb-23      NaN  Production Technician I   \n",
       "2           2    Edward     Buck  10-Dec-18      NaN       Area Sales Manager   \n",
       "3           3   Michael  Riordan  21-Jun-21      NaN       Area Sales Manager   \n",
       "4           4   Jasmine    Onque  29-Jun-19      NaN       Area Sales Manager   \n",
       "\n",
       "        Supervisor                        ADEmail BusinessUnit EmployeeStatus  \\\n",
       "0     Peter Oneill    uriah.bridges@bilearner.com         CCDR         Active   \n",
       "1  Renee Mccormick      paula.small@bilearner.com           EW         Active   \n",
       "2   Crystal Walker      edward.buck@bilearner.com           PL         Active   \n",
       "3   Rebekah Wright  michael.riordan@bilearner.com         CCDR         Active   \n",
       "4        Jason Kim    jasmine.onque@bilearner.com          TNS         Active   \n",
       "\n",
       "   ... Satisfaction Score Work-Life Balance Score Training Date  \\\n",
       "0  ...                  2                       3     15-Jul-23   \n",
       "1  ...                  1                       5     12-Sep-22   \n",
       "2  ...                  2                       1     13-Aug-22   \n",
       "3  ...                  5                       4     15-Dec-22   \n",
       "4  ...                  5                       3     13-Jul-23   \n",
       "\n",
       "    Training Program Name Training Type Training Outcome          Location  \\\n",
       "0  Leadership Development      Internal           Failed      South Marisa   \n",
       "1        Customer Service      External       Incomplete       Tammieville   \n",
       "2  Leadership Development      External           Failed  East Roberthaven   \n",
       "3      Project Management      External        Completed         Garzatown   \n",
       "4        Technical Skills      External           Failed   Lake Meganville   \n",
       "\n",
       "               Trainer Training Duration(Days) Training Cost  \n",
       "0     Taylor Rodriguez                       2        606.11  \n",
       "1  Kelly Patterson DDS                       4        673.02  \n",
       "2        Taylor Thomas                       2        413.28  \n",
       "3        Holly Elliott                       3        663.78  \n",
       "4      Donald Martinez                       5        399.03  \n",
       "\n",
       "[5 rows x 39 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import boto3\n",
    "import pandas as pd\n",
    "from io import StringIO\n",
    "\n",
    "# S3 Credential\n",
    "aws_access_key_id = \"admin\"\n",
    "aws_secret_access_key = \"password\"\n",
    "\n",
    "# Create S3 Client for MinIO\n",
    "s3 = boto3.client(\n",
    "    \"s3\",\n",
    "    aws_access_key_id=aws_access_key_id,\n",
    "    aws_secret_access_key=aws_secret_access_key,\n",
    "    endpoint_url=\"http://minio:9000\",  # MinIO endpoint\n",
    "    use_ssl=False\n",
    ")\n",
    "\n",
    "# Bucket Name\n",
    "bucket_name = \"landing-data\"\n",
    "\n",
    "# List objects in bucket\n",
    "response = s3.list_objects_v2(Bucket=bucket_name)\n",
    "objects_list = response.get(\"Contents\", [])\n",
    "\n",
    "# Loop through objects and read CSV into Pandas DataFrame\n",
    "dfs = []  # list to store DataFrames\n",
    "for obj in objects_list:\n",
    "    obj_name = obj[\"Key\"]\n",
    "    response = s3.get_object(Bucket=bucket_name, Key=obj_name)\n",
    "    object_content = response[\"Body\"].read().decode(\"utf-8\")\n",
    "\n",
    "    # Convert CSV text to Pandas DataFrame\n",
    "    df = pd.read_csv(StringIO(object_content))\n",
    "    dfs.append(df)\n",
    "\n",
    "# Combine all files into a single DataFrame (optional)\n",
    "final_df = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "final_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8254ed08-93c0-492e-83b0-be5321e9e88b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to load data into lakehouse_prod_catalog.raw_bronze_zone.raw_bronze_hris_data: name 'mode' is not defined\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'mode' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[20]\u001b[39m\u001b[32m, line 7\u001b[39m\n\u001b[32m      5\u001b[39m df_spark = spark.createDataFrame(final_df)\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m     df_spark.write.mode(\u001b[43mmode\u001b[49m).format(\u001b[33m\"\u001b[39m\u001b[33mparquet\u001b[39m\u001b[33m\"\u001b[39m).saveAsTable(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcatalog\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mschema\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtable_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m      8\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mSuccessfully load data into \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcatalog\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mschema\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtable_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[31mNameError\u001b[39m: name 'mode' is not defined"
     ]
    }
   ],
   "source": [
    "catalog = 'lakehouse_prod_catalog'\n",
    "schema = 'raw_bronze_zone'\n",
    "table_name = 'raw_bronze_hris_data'\n",
    "\n",
    "df_spark = spark.createDataFrame(final_df)\n",
    "try:\n",
    "    df_spark.write.mode(mode).format(\"parquet\").saveAsTable(f\"{catalog}.{schema}.{table_name}\")\n",
    "    print(f\"Successfully load data into {catalog}.{schema}.{table_name}\")\n",
    "except Exception as e:\n",
    "    print(f\"Failed to load data into {catalog}.{schema}.{table_name}: {e}\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5769e0ad-b930-4700-b739-8c0fa96b6770",
   "metadata": {},
   "outputs": [
    {
     "ename": "AnalysisException",
     "evalue": "[TABLE_OR_VIEW_NOT_FOUND] The table or view `lakehouse_prod_catalog`.`raw_bronze_zone`.`bronze_hris_employee` cannot be found. Verify the spelling and correctness of the schema and catalog.\nIf you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.\nTo tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS.; line 1 pos 14;\n'Project [*]\n+- 'UnresolvedRelation [lakehouse_prod_catalog, raw_bronze_zone, bronze_hris_employee], [], false\n",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAnalysisException\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[31]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Query the data from the table\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[43mspark\u001b[49m\u001b[43m.\u001b[49m\u001b[43msql\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mSELECT * FROM lakehouse_prod_catalog.raw_bronze_zone.bronze_hris_employee\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m.show()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/spark/python/pyspark/sql/session.py:1631\u001b[39m, in \u001b[36mSparkSession.sql\u001b[39m\u001b[34m(self, sqlQuery, args, **kwargs)\u001b[39m\n\u001b[32m   1627\u001b[39m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m._jvm \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1628\u001b[39m         litArgs = \u001b[38;5;28mself\u001b[39m._jvm.PythonUtils.toArray(\n\u001b[32m   1629\u001b[39m             [_to_java_column(lit(v)) \u001b[38;5;28;01mfor\u001b[39;00m v \u001b[38;5;129;01min\u001b[39;00m (args \u001b[38;5;129;01mor\u001b[39;00m [])]\n\u001b[32m   1630\u001b[39m         )\n\u001b[32m-> \u001b[39m\u001b[32m1631\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m DataFrame(\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_jsparkSession\u001b[49m\u001b[43m.\u001b[49m\u001b[43msql\u001b[49m\u001b[43m(\u001b[49m\u001b[43msqlQuery\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlitArgs\u001b[49m\u001b[43m)\u001b[49m, \u001b[38;5;28mself\u001b[39m)\n\u001b[32m   1632\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m   1633\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(kwargs) > \u001b[32m0\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/java_gateway.py:1322\u001b[39m, in \u001b[36mJavaMember.__call__\u001b[39m\u001b[34m(self, *args)\u001b[39m\n\u001b[32m   1316\u001b[39m command = proto.CALL_COMMAND_NAME +\\\n\u001b[32m   1317\u001b[39m     \u001b[38;5;28mself\u001b[39m.command_header +\\\n\u001b[32m   1318\u001b[39m     args_command +\\\n\u001b[32m   1319\u001b[39m     proto.END_COMMAND_PART\n\u001b[32m   1321\u001b[39m answer = \u001b[38;5;28mself\u001b[39m.gateway_client.send_command(command)\n\u001b[32m-> \u001b[39m\u001b[32m1322\u001b[39m return_value = \u001b[43mget_return_value\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1323\u001b[39m \u001b[43m    \u001b[49m\u001b[43manswer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgateway_client\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtarget_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1325\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n\u001b[32m   1326\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(temp_arg, \u001b[33m\"\u001b[39m\u001b[33m_detach\u001b[39m\u001b[33m\"\u001b[39m):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/spark/python/pyspark/errors/exceptions/captured.py:185\u001b[39m, in \u001b[36mcapture_sql_exception.<locals>.deco\u001b[39m\u001b[34m(*a, **kw)\u001b[39m\n\u001b[32m    181\u001b[39m converted = convert_exception(e.java_exception)\n\u001b[32m    182\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(converted, UnknownException):\n\u001b[32m    183\u001b[39m     \u001b[38;5;66;03m# Hide where the exception came from that shows a non-Pythonic\u001b[39;00m\n\u001b[32m    184\u001b[39m     \u001b[38;5;66;03m# JVM exception message.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m185\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m converted \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    186\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    187\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "\u001b[31mAnalysisException\u001b[39m: [TABLE_OR_VIEW_NOT_FOUND] The table or view `lakehouse_prod_catalog`.`raw_bronze_zone`.`bronze_hris_employee` cannot be found. Verify the spelling and correctness of the schema and catalog.\nIf you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.\nTo tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS.; line 1 pos 14;\n'Project [*]\n+- 'UnresolvedRelation [lakehouse_prod_catalog, raw_bronze_zone, bronze_hris_employee], [], false\n"
     ]
    }
   ],
   "source": [
    "# Query the data from the table\n",
    "spark.sql(\"SELECT * FROM lakehouse_prod_catalog.raw_bronze_zone.bronze_hris_employee\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0824789c-b980-4470-8c18-ea627a7764ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------------------+---------------------+---------------+-------------+----------+------------------+------------+------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+--------------------+-----------+\n",
      "|VendorID|tpep_pickup_datetime|tpep_dropoff_datetime|passenger_count|trip_distance|RatecodeID|store_and_fwd_flag|PULocationID|DOLocationID|payment_type|fare_amount|extra|mta_tax|tip_amount|tolls_amount|improvement_surcharge|total_amount|congestion_surcharge|airport_fee|\n",
      "+--------+--------------------+---------------------+---------------+-------------+----------+------------------+------------+------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+--------------------+-----------+\n",
      "|       1| 2021-04-01 00:00:18|  2021-04-01 00:21:54|            1.0|          8.4|       1.0|                 N|          79|         116|           1|       25.5|  3.0|    0.5|      5.85|         0.0|                  0.3|       35.15|                 2.5|        0.0|\n",
      "|       1| 2021-04-01 00:42:37|  2021-04-01 00:46:23|            1.0|          0.9|       1.0|                 N|          75|         236|           2|        5.0|  3.0|    0.5|       0.0|         0.0|                  0.3|         8.8|                 2.5|        0.0|\n",
      "|       1| 2021-04-01 00:57:56|  2021-04-01 01:08:22|            1.0|          3.4|       1.0|                 N|         236|         168|           2|       11.5|  3.0|    0.5|       0.0|         0.0|                  0.3|        15.3|                 2.5|        0.0|\n",
      "|       1| 2021-04-01 00:01:58|  2021-04-01 00:54:27|            1.0|          0.0|       1.0|                 N|          47|          61|           1|       44.2|  0.0|    0.5|       0.0|         0.0|                  0.3|        45.0|                 0.0|        0.0|\n",
      "|       2| 2021-04-01 00:24:55|  2021-04-01 00:34:33|            1.0|         1.96|       1.0|                 N|         238|         152|           1|        9.0|  0.5|    0.5|      3.09|         0.0|                  0.3|       13.39|                 0.0|        0.0|\n",
      "|       2| 2021-04-01 00:19:16|  2021-04-01 00:21:46|            1.0|         0.77|       1.0|                 N|         142|         238|           1|        4.5|  0.5|    0.5|      1.24|         0.0|                  0.3|        9.54|                 2.5|        0.0|\n",
      "|       2| 2021-04-01 00:25:11|  2021-04-01 00:31:53|            1.0|         3.65|       1.0|                 N|         238|         244|           1|       11.5|  0.5|    0.5|      2.56|         0.0|                  0.3|       15.36|                 0.0|        0.0|\n",
      "|       1| 2021-04-01 00:27:53|  2021-04-01 00:47:03|            0.0|          8.9|       1.0|                 N|         138|         239|           1|       26.5|  3.0|    0.5|      7.25|        6.12|                  0.3|       43.67|                 2.5|        0.0|\n",
      "|       2| 2021-04-01 00:24:24|  2021-04-01 00:37:50|            1.0|         2.98|       1.0|                 N|         151|         244|           2|       12.0|  0.5|    0.5|       0.0|         0.0|                  0.3|        13.3|                 0.0|        0.0|\n",
      "|       1| 2021-04-01 00:19:18|  2021-04-01 00:41:25|            1.0|          8.9|       1.0|                 N|         132|         196|           2|       28.0|  0.5|    0.5|       0.0|         0.0|                  0.3|        29.3|                 0.0|        0.0|\n",
      "+--------+--------------------+---------------------+---------------+-------------+----------+------------------+------------+------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+--------------------+-----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Extract a Data\n",
    "df = spark.read.parquet(\"/home/iceberg/data/yellow_tripdata_2021-04.parquet\")\n",
    "df.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a5f399e4-7c04-425e-87cc-5e9970d80381",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "df.writeTo(\"lakehouse_prod_catalog.test_db.test_table_001\").createOrReplace()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "fc8b1ba2-fab9-45a1-8f72-01fb5612a077",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------------------+---------------------+---------------+-------------+----------+------------------+------------+------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+--------------------+-----------+\n",
      "|VendorID|tpep_pickup_datetime|tpep_dropoff_datetime|passenger_count|trip_distance|RatecodeID|store_and_fwd_flag|PULocationID|DOLocationID|payment_type|fare_amount|extra|mta_tax|tip_amount|tolls_amount|improvement_surcharge|total_amount|congestion_surcharge|airport_fee|\n",
      "+--------+--------------------+---------------------+---------------+-------------+----------+------------------+------------+------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+--------------------+-----------+\n",
      "|       1| 2021-04-01 00:00:18|  2021-04-01 00:21:54|            1.0|          8.4|       1.0|                 N|          79|         116|           1|       25.5|  3.0|    0.5|      5.85|         0.0|                  0.3|       35.15|                 2.5|        0.0|\n",
      "|       1| 2021-04-01 00:42:37|  2021-04-01 00:46:23|            1.0|          0.9|       1.0|                 N|          75|         236|           2|        5.0|  3.0|    0.5|       0.0|         0.0|                  0.3|         8.8|                 2.5|        0.0|\n",
      "|       1| 2021-04-01 00:57:56|  2021-04-01 01:08:22|            1.0|          3.4|       1.0|                 N|         236|         168|           2|       11.5|  3.0|    0.5|       0.0|         0.0|                  0.3|        15.3|                 2.5|        0.0|\n",
      "|       1| 2021-04-01 00:01:58|  2021-04-01 00:54:27|            1.0|          0.0|       1.0|                 N|          47|          61|           1|       44.2|  0.0|    0.5|       0.0|         0.0|                  0.3|        45.0|                 0.0|        0.0|\n",
      "|       2| 2021-04-01 00:24:55|  2021-04-01 00:34:33|            1.0|         1.96|       1.0|                 N|         238|         152|           1|        9.0|  0.5|    0.5|      3.09|         0.0|                  0.3|       13.39|                 0.0|        0.0|\n",
      "|       2| 2021-04-01 00:19:16|  2021-04-01 00:21:46|            1.0|         0.77|       1.0|                 N|         142|         238|           1|        4.5|  0.5|    0.5|      1.24|         0.0|                  0.3|        9.54|                 2.5|        0.0|\n",
      "|       2| 2021-04-01 00:25:11|  2021-04-01 00:31:53|            1.0|         3.65|       1.0|                 N|         238|         244|           1|       11.5|  0.5|    0.5|      2.56|         0.0|                  0.3|       15.36|                 0.0|        0.0|\n",
      "|       1| 2021-04-01 00:27:53|  2021-04-01 00:47:03|            0.0|          8.9|       1.0|                 N|         138|         239|           1|       26.5|  3.0|    0.5|      7.25|        6.12|                  0.3|       43.67|                 2.5|        0.0|\n",
      "|       2| 2021-04-01 00:24:24|  2021-04-01 00:37:50|            1.0|         2.98|       1.0|                 N|         151|         244|           2|       12.0|  0.5|    0.5|       0.0|         0.0|                  0.3|        13.3|                 0.0|        0.0|\n",
      "|       1| 2021-04-01 00:19:18|  2021-04-01 00:41:25|            1.0|          8.9|       1.0|                 N|         132|         196|           2|       28.0|  0.5|    0.5|       0.0|         0.0|                  0.3|        29.3|                 0.0|        0.0|\n",
      "+--------+--------------------+---------------------+---------------+-------------+----------+------------------+------------+------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+--------------------+-----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "read_df = spark.read.table(\"lakehouse_prod_catalog.test_db.test_table_001\")\n",
    "read_df.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5b2e2051-2a8d-4918-ba96-94aa34ec49e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "# df.write.mode(\"overwrite\").format(\"parquet\").saveAsTable(\"test_db.test_table_001\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2e08e5a9-5710-4e62-87e6-88db07742ccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Try with Nessie Catalog\n",
    "# # df.write.mode(\"overwrite\").format(\"iceberg\").saveAsTable(\"nessie.test_db.test_table_002\")\n",
    "# df.writeTo(\"test_db.test_table_002\").using(\"iceberg\").createOrReplace()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ece88222-56d1-41be-bd8b-5b94c0885926",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|             catalog|\n",
      "+--------------------+\n",
      "|lakehouse_prod_ca...|\n",
      "|       spark_catalog|\n",
      "+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Show Catalog\n",
    "spark.sql(\"SHOW CATALOGS\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "95ca4d9c-a662-438b-b8d3-1f4753a93947",
   "metadata": {},
   "outputs": [],
   "source": [
    "# spark.sql(\"SHOW NAMESPACES IN lakehouse_prod_catalog\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6c672a65-9a68-4b9c-a015-64a199fe1d73",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7c5b6f22-25b1-4dcc-a232-11260729ffc3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - hive</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://95ac209e1b97:4041\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.5.6</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>PySparkShell</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x705828231040>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "624e05f0-12c2-4483-bb3c-c951c4b6f50d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f689fe44-c49a-4116-b1fb-6ff7fe4acf25",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
